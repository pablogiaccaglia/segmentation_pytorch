{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%rm -r segmentation_pytorch/\n",
        "!git clone https://github.com/pablogiaccaglia/segmentation_pytorch\n",
        "!pip install git+https://github.com/pablogiaccaglia/segmentation_pytorch\n",
        "%cd /content/segmentation_pytorch/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pe6gTSPU6d3x",
        "outputId": "097071c8-70eb-4fa3-e7de-60eaf3521656"
      },
      "id": "Pe6gTSPU6d3x",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'segmentation_pytorch'...\n",
            "remote: Enumerating objects: 290, done.\u001b[K\n",
            "remote: Counting objects: 100% (177/177), done.\u001b[K\n",
            "remote: Compressing objects: 100% (125/125), done.\u001b[K\n",
            "remote: Total 290 (delta 111), reused 101 (delta 51), pack-reused 113\u001b[K\n",
            "Receiving objects: 100% (290/290), 147.80 MiB | 13.31 MiB/s, done.\n",
            "Resolving deltas: 100% (165/165), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/pablogiaccaglia/segmentation_pytorch\n",
            "  Cloning https://github.com/pablogiaccaglia/segmentation_pytorch to /tmp/pip-req-build-01d2i62v\n",
            "  Running command git clone -q https://github.com/pablogiaccaglia/segmentation_pytorch /tmp/pip-req-build-01d2i62v\n",
            "\u001b[31mERROR: File \"setup.py\" not found for legacy project git+https://github.com/pablogiaccaglia/segmentation_pytorch.\u001b[0m\n",
            "/content/segmentation_pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Google Drive connection**\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "7tCW-rqND51V",
        "outputId": "7d5d454e-ca05-4ee8-ff16-dcae566b50a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "7tCW-rqND51V",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "57ef2ace",
      "metadata": {
        "id": "57ef2ace",
        "outputId": "7276aef3-f55a-41fa-9654-25310d83e164",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.8/dist-packages (0.6.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.8/dist-packages (0.19.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow_addons) (21.3)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow_addons) (2.7.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow_addons) (3.0.9)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.8/dist-packages (0.6.12)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from timm) (0.14.0+cu116)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.8/dist-packages (from timm) (1.13.0+cu116)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from timm) (6.0)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.8/dist-packages (from timm) (0.11.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.7->timm) (4.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (21.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (4.64.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (3.8.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.9->huggingface-hub->timm) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub->timm) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub->timm) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub->timm) (2022.12.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub->timm) (1.24.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision->timm) (1.21.6)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: mmcv in /usr/local/lib/python3.8/dist-packages (1.7.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from mmcv) (6.0)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.8/dist-packages (from mmcv) (0.32.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from mmcv) (7.1.2)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.8/dist-packages (from mmcv) (2.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from mmcv) (21.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from mmcv) (1.21.6)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->mmcv) (3.0.9)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.8/dist-packages (2.5.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (1.21.6)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (3.19.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchviz in /usr/local/lib/python3.8/dist-packages (0.0.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.8/dist-packages (from torchviz) (0.10.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from torchviz) (1.13.0+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->torchviz) (4.4.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: yacs in /usr/local/lib/python3.8/dist-packages (0.1.8)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from yacs) (6.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kornia in /usr/local/lib/python3.8/dist-packages (0.6.8)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from kornia) (1.13.0+cu116)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from kornia) (21.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.8.1->kornia) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->kornia) (3.0.9)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import cv2\n",
        "import time\n",
        "import timeit\n",
        "import random\n",
        "import pathlib\n",
        "import logging\n",
        "import numpy as np\n",
        "import albumentations\n",
        "from tqdm import tqdm\n",
        "from functools import partial\n",
        "from typing import Tuple, List\n",
        "import sys\n",
        "!{sys.executable} -m pip install einops\n",
        "!{sys.executable} -m pip install tensorflow_addons\n",
        "!{sys.executable} -m pip install timm\n",
        "!{sys.executable} -m pip install mmcv\n",
        "!{sys.executable} -m pip install tensorboardX\n",
        "!{sys.executable} -m pip install torchviz\n",
        "!{sys.executable} -m pip install yacs\n",
        "!{sys.executable} -m pip install kornia\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from mmcv.runner import build_optimizer\n",
        "from tensorboardX import SummaryWriter\n",
        "import matplotlib.pyplot as plt\n",
        "from torchviz import make_dot\n",
        "from models.segformer import Segformer\n",
        "\n",
        "#%config InlineBackend.figure_format = 'retina'\n",
        "plt.style.use('ggplot')\n",
        "plt.rc('xtick',labelsize=16)\n",
        "plt.rc('ytick',labelsize=16)\n",
        "\n",
        "from utils.label_utils import get_labels\n",
        "from utils.lr_schedule import PolyLrUpdater\n",
        "from utils.modelsummary import get_model_summary\n",
        "from utils.runners import train, validate, testval\n",
        "from utils.data_utils import label_mapping, SegmentationDataset, display, cityscapes_label_to_rgb\n",
        "from utils.train_utils import AverageMeter, CrossEntropy, BinaryCrossEntropy, get_confusion_matrix, create_logger\n",
        "from utils.transformations import (ComposeDouble, FunctionWrapperDouble, normalize, re_normalize,\n",
        "                                   random_crop, random_resize, random_brightness, AlbuSeg2d, scale_aug)\n",
        "from utils.customlosses import FocalTverskyLoss\n",
        "\n",
        "from configs.segformer_config import config as cfg\n",
        "\n",
        "labels = get_labels()\n",
        "id2label =      { label.id      : label for label in labels }\n",
        "trainid2label = { label.trainId : label for label in labels }\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Data Loader**\n",
        "\n",
        "def loadNumpyArrays(folderPath: str, arr, max, channels_first = False) -> np.ndarray:\n",
        "    i = 0\n",
        "\n",
        "    entries = os.listdir(folderPath)\n",
        "    entries.sort()\n",
        "    #print(entries)\n",
        "    print(len(entries))\n",
        "    for entry in entries:\n",
        "\n",
        "      if i==len(arr):\n",
        "        break\n",
        "\n",
        "      if \".DS_Store\" not in str(entry) and \"(1).npy\" not in str(entry):\n",
        "\n",
        "        l = np.load(folderPath + entry)\n",
        "        #print(l.shape)\n",
        "\n",
        "        if \"IMG\" in folderPath:\n",
        "          # l = tf.keras.applications.vgg16.preprocess_input(l)\n",
        "          pass\n",
        "        else:\n",
        "          l = np.squeeze(l)\n",
        "        \n",
        "        arr[i] = l\n",
        "        i = i + 1\n",
        "        if i==max:\n",
        "          break\n",
        "\n",
        "    if channels_first:\n",
        "      try:\n",
        "        arr = np.transpose(arr, (0, 3, 1, 2))\n",
        "      except:\n",
        "         pass\n",
        "    \n",
        "    return arr\n",
        "\n",
        "def getDatasetArraysForNet() -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
        "    trainingImgDir = \"/content/drive/MyDrive/Arrays-cbis-BIG/Dataset-split-arrays/Training-Final-IMG-Arrayss/\"\n",
        "    trainingMaskDir = \"/content/drive/MyDrive/Arrays-cbis-BIG/Dataset-split-arrays/Training-Final-MSK-Arrays/\"\n",
        "    validationImgDir = \"/content/drive/MyDrive/Arrays-cbis-BIG/Dataset-split-arrays/Validation-Final-IMG-Arrays/\"\n",
        "    validationMaskDir = \"/content/drive/MyDrive/Arrays-cbis-BIG/Dataset-split-arrays/Validation-Final-MSK-Arrays/\"\n",
        "    testingImgDir = \"/content/drive/MyDrive/Arrays-cbis-BIG/Dataset-split-arrays/Testing-Final-IMG-Arrays/\"\n",
        "    testingMaskDir = \"/content/drive/MyDrive/Arrays-cbis-BIG/Dataset-split-arrays/Testing-Final-MSK-Arrays/\"\n",
        "\n",
        "    h = w = 256\n",
        "    batch11 = 7740\n",
        "    batch12 = 1550\n",
        "    batch2  = 1000\n",
        "    channels_first = True\n",
        "\n",
        "    dim1 = (batch11, h, w)\n",
        "    dim2 = (batch11, h, w)\n",
        "    dim3 = (batch12, h, w)\n",
        "    dim4 = (batch12, h, w)\n",
        "    dim5 = (batch2, h, w)\n",
        "    dim6 = (batch2, h, w)\n",
        "\n",
        "\n",
        "    return loadNumpyArrays(folderPath = trainingImgDir, arr = np.ndarray(dim1, dtype = 'float32'), max = 7749, channels_first = channels_first), \\\n",
        "           loadNumpyArrays(folderPath = trainingMaskDir, arr = np.ndarray(dim2, dtype = 'uint8'), max = 7749, channels_first = channels_first), \\\n",
        "           loadNumpyArrays(folderPath = validationImgDir, arr = np.ndarray(dim3, dtype = 'float32'), max = 1551, channels_first = channels_first), \\\n",
        "           loadNumpyArrays( folderPath = validationMaskDir, arr = np.ndarray(dim4, dtype = 'uint8'), max = 1551, channels_first = channels_first), \\\n",
        "           loadNumpyArrays(folderPath = testingImgDir, arr = np.ndarray(dim5, dtype = 'float32'), max = 1000), \\\n",
        "           loadNumpyArrays(folderPath = testingMaskDir, arr = np.ndarray(dim6, dtype = 'uint8'), max = 1000, channels_first = channels_first)"
      ],
      "metadata": {
        "id": "m0GEFGJN_lSK"
      },
      "id": "m0GEFGJN_lSK",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b64ce1a4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b64ce1a4",
        "outputId": "7f434a9d-7804-43e3-98fb-d2d1b91330f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7749\n",
            "7749\n",
            "1551\n",
            "1551\n",
            "1035\n",
            "1035\n"
          ]
        }
      ],
      "source": [
        "imgs_train, imgs_mask_train, imgs_val, imgs_mask_val, imgs_test, imgs_mask_test_gt = getDatasetArraysForNet()\n",
        "\n",
        "mean = 0.44531356896770125\n",
        "std = 0.2692461874154524\n",
        "\n",
        "imgs_train = imgs_train / 255.\n",
        "imgs_val = imgs_val / 255.\n",
        "imgs_test = imgs_test / 255.\n",
        "\n",
        "\n",
        "imgs_train = (imgs_train - mean) / std\n",
        "imgs_val = (imgs_val-mean) / std\n",
        "imgs_test = (imgs_test-mean) / std\n",
        "\n",
        "def getTensorDataset(x, y):\n",
        "  return TensorDataset(torch.Tensor(x), torch.Tensor(y))\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    dataset = getTensorDataset(imgs_train, imgs_mask_train), \n",
        "    batch_size = 8, \n",
        "    shuffle = True,\n",
        "    drop_last = True, # WHY DROPPING THE LAST BATCH IF NOT BATCH_SIZE COMPATIBLE?\n",
        "    num_workers = 4, # HOW MANY SUB-PROCESSES USE FOR DATA LOADING\n",
        "    prefetch_factor = 8, \n",
        "    pin_memory=True # the data loader will copy Tensors into device/CUDA pinned memory before returning them\n",
        "    \n",
        ")\n",
        "valid_dataloader = DataLoader(\n",
        "    dataset =getTensorDataset(imgs_val, imgs_mask_val), \n",
        "    batch_size = 8, \n",
        "    shuffle = True,\n",
        "    drop_last = True,\n",
        "    num_workers = 4,\n",
        "    prefetch_factor = 8,\n",
        "    pin_memory=True\n",
        "    \n",
        ")\n",
        "\n",
        "x, y = next(iter(train_dataloader)) # first training sample\n",
        "xv, yv = next(iter(valid_dataloader)) # first validation sample\n",
        "\n",
        "\n",
        "\n",
        "x_min, x_max = x.min(), x.max()\n",
        "print('x.shape: {}, x.type: {}, [min(x), max(x)]: [{:.3f}, {:.3f}]'.format(x.numpy().shape, x.dtype, x_min, x_max))\n",
        "print('y.shape: {}, y.type: {} \\ny unique: {}'.format(y.numpy().shape, y.dtype, np.unique(y.numpy()).tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(xv.shape)"
      ],
      "metadata": {
        "id": "vwC-8uNOF1i0"
      },
      "id": "vwC-8uNOF1i0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b689971",
      "metadata": {
        "id": "9b689971"
      },
      "outputs": [],
      "source": [
        "def mammograms_label_to_rgb(mask):\n",
        "    h = mask.shape[0]\n",
        "    w = mask.shape[1]\n",
        "    print(mask.shape)\n",
        "    mask_rgb = np.zeros((h, w, 3), dtype=np.uint8)\n",
        "    for key, val in trainid2label.items():\n",
        "        indices = mask == key\n",
        "        mask_rgb[indices.squeeze()] = val.color \n",
        "    return mask_rgb\n",
        "\n",
        "\n",
        "def display_blend(display_list):\n",
        "    plt.figure(figsize=(10, 10), dpi=200)\n",
        "    for i in range(len(display_list)):\n",
        "        blend = cv2.addWeighted(display_list[i][0], 0.8, display_list[i][1], 0.6, 0)\n",
        "        plt.subplot(1, len(display_list), i+1)\n",
        "        plt.imshow(blend)\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(labels)"
      ],
      "metadata": {
        "id": "uwpi8wLcPlih"
      },
      "id": "uwpi8wLcPlih",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xv, yv = next(iter(valid_dataloader)) # first validation sample\n",
        "xv = torch.stack([xv,xv,xv], 1)\n",
        "\n",
        "print(xv.shape)"
      ],
      "metadata": {
        "id": "GxHTka4SGWx6"
      },
      "id": "GxHTka4SGWx6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, batch in enumerate(valid_dataloader):\n",
        "  x, y = batch\n",
        "\n",
        "  x = torch.stack([x,x,x], 1)\n",
        "  display_blend([\n",
        "    [re_normalize(x[0].permute(1,2,0).numpy()), mammograms_label_to_rgb(y[0])],\n",
        "    [re_normalize(x[0].permute(1,2,0).numpy()), mammograms_label_to_rgb(y[0])]\n",
        "  ])\n",
        "\n",
        "  print(x)\n",
        "  break"
      ],
      "metadata": {
        "id": "9feH7DBAYCMh"
      },
      "id": "9feH7DBAYCMh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba023148",
      "metadata": {
        "scrolled": false,
        "id": "ba023148"
      },
      "outputs": [],
      "source": [
        "idx1 = 0\n",
        "idx2 = 1\n",
        "display_blend([\n",
        "    [re_normalize(xv[idx1].permute(1,2,0).numpy()), mammograms_label_to_rgb(yv[idx1])],\n",
        "    [re_normalize(xv[idx2].permute(1,2,0).numpy()), mammograms_label_to_rgb(yv[idx2])]\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "526f5ea7",
      "metadata": {
        "id": "526f5ea7"
      },
      "outputs": [],
      "source": [
        "SEG_CFG = cfg.MODEL.B3\n",
        "cfg.NUM_CLASSES = 1\n",
        "print(SEG_CFG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fb611bd",
      "metadata": {
        "scrolled": true,
        "id": "4fb611bd"
      },
      "outputs": [],
      "source": [
        "model = Segformer(\n",
        "    pretrained = None, # CHECK THIS TO LOAD PRETRAINED MODEL\n",
        "    img_size = 512, \n",
        "    patch_size = cfg.MODEL.PATCH_SIZE, \n",
        "    num_classes = 1,\n",
        "    embed_dims = SEG_CFG.CHANNEL_DIMS, \n",
        "    num_heads = SEG_CFG.NUM_HEADS, \n",
        "    mlp_ratios = SEG_CFG.MLP_RATIOS,\n",
        "    qkv_bias = SEG_CFG.QKV_BIAS, \n",
        "    depths = SEG_CFG.DEPTHS, \n",
        "    sr_ratios = SEG_CFG.SR_RATIOS,\n",
        "    drop_rate = SEG_CFG.DROP_RATE, \n",
        "    drop_path_rate = SEG_CFG.DROP_PATH_RATE,\n",
        "    decoder_dim = SEG_CFG.DECODER_DIM,\n",
        "    norm_layer = partial(nn.LayerNorm, eps=1e-6), \n",
        "    shift_patch_tokenization = True\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5443a1c9",
      "metadata": {
        "id": "5443a1c9"
      },
      "outputs": [],
      "source": [
        "#w = torch.FloatTensor([1,1])\n",
        "\n",
        "# binary classification loss function\n",
        "criterion = FocalTverskyLoss(\n",
        ").to(device)\n",
        "\n",
        "# configuration for the model's optimizer\n",
        "optimizer_cfg = dict(\n",
        "    type='Adam', #AdamW\n",
        "    lr=1e-4)  #  0.00006)\n",
        "\n",
        "# build model optimizer\n",
        "optimizer = build_optimizer(model, optimizer_cfg)\n",
        "\n",
        "\n",
        "# A LearningRateSchedule that uses a polynomial decay schedule\n",
        "lr_scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=1e-5, max_lr=1e-4, cycle_momentum=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x2 =  F.interpolate(x, size = 512, mode = 'bilinear', align_corners = False)"
      ],
      "metadata": {
        "id": "DvFn2KguyXYb"
      },
      "id": "DvFn2KguyXYb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "details = get_model_summary(model, x2.cuda(), verbose=True)\n",
        "print(details)"
      ],
      "metadata": {
        "id": "DXIGscAjTQgn"
      },
      "id": "DXIGscAjTQgn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "P2q6Kvho3Onj"
      },
      "id": "P2q6Kvho3Onj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "574acd17",
      "metadata": {
        "id": "574acd17"
      },
      "outputs": [],
      "source": [
        "!{sys.executable} -m pip install torchmetrics\n",
        "from torchmetrics import JaccardIndex\n",
        "def train(\n",
        "    cfg, \n",
        "    dataloader, \n",
        "    model, \n",
        "    loss_fn, \n",
        "    optimizer, \n",
        "    lr_scheduler, \n",
        "    scaler, \n",
        "    writer_dict,\n",
        "    epoch, \n",
        "):\n",
        "    model.train()\n",
        "    \n",
        "    ave_loss = AverageMeter() # object to compute and store the average and current value\n",
        "    steps_tot = epoch*len(dataloader) # overall amount of steps, as the number of total passes of samples in the network (e.g epoch = 2, len(dataloander) = batch_size = 5, steps_tot = 10)\n",
        "    writer = writer_dict['writer']\n",
        "    global_steps = writer_dict['train_global_steps'] # global steps are the so far total number of epochs completed\n",
        "    \n",
        "    # loops over each batch (e.g: size 2 batch)\n",
        "    for step, batch in enumerate(dataloader):\n",
        "        X, y = batch # input, target\n",
        "        X = torch.stack([X,X,X], 1)\n",
        "        X = F.interpolate(X, size = 512, mode = 'bilinear', align_corners = False)\n",
        "        X, y = X.cuda(), y.long().cuda()\n",
        "        \n",
        "        # Compute prediction and loss\n",
        "        with torch.cuda.amp.autocast():\n",
        "            pred = model(X.contiguous()) # Returns a contiguous in memory tensor containing the same data as self tensor\n",
        "            pred = F.interpolate(pred, size = cfg.DATASET.CROP_SIZE, mode = 'bilinear', align_corners = False) # since the model's output is (64x64), it has to be rescaled to same size as input\n",
        "            losses = loss_fn(torch.squeeze(pred), y) # computes loss for each sample\n",
        "        loss = losses.mean() # single loss that is the averge of all the losses of the batch\n",
        "        \n",
        "        # Normalize loss to account for batch accumulation\n",
        "        loss = loss / cfg.TRAIN.ACCUM_STEPS \n",
        "            \n",
        "        # Backward pass to compute the gradients\n",
        "        scaler.scale(loss).backward()\n",
        "        \n",
        "        # Weight update\n",
        "        if ((step + 1) % cfg.TRAIN.ACCUM_STEPS == 0) or (step + 1 == len(dataloader)):\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad() # set the gradients to 0 after updating the weights, in this way the next accumulation of gradients starts from 0 gradient\n",
        "\n",
        "            # update average loss <- WHY JUST THE FINAL LOSS IS CONSIDERED??????\n",
        "            ave_loss.update(loss.item())\n",
        "\n",
        "            print(\"\\r\", ave_loss.average(), end=\"\")\n",
        "            # update learning schedule\n",
        "            lr_scheduler.step()\n",
        "            lr = lr_scheduler.get_lr()\n",
        "        \n",
        "        \n",
        "    writer.add_scalar('train_loss', ave_loss.average(), global_steps) # current AVERAGE TRAINING LOSS\n",
        "    writer_dict['train_global_steps'] = global_steps + 1 # UPDATES EPOCH STEP\n",
        "    \n",
        "    \n",
        "def validate(\n",
        "    cfg, \n",
        "    dataloader, \n",
        "    model, \n",
        "    loss_fn, \n",
        "    writer_dict\n",
        "):\n",
        "    model.eval() \n",
        "    \n",
        "    ave_loss = AverageMeter()  # object to compute and store the average and current value\n",
        "    iter_steps = len(dataloader.dataset) // cfg.TRAIN.BATCH_SIZE # computes the number of steps required for a single pass of the whole dataset, given the batch size\n",
        "    confusion_matrix = np.zeros((cfg.DATASET.NUM_CLASSES, cfg.DATASET.NUM_CLASSES, 1))\n",
        "\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(dataloader):\n",
        "            X, y = batch\n",
        "            X = torch.stack([X,X,X], 1)\n",
        "            X = F.interpolate(X, size = 512, mode = 'bilinear', align_corners = False)\n",
        "            X, y = X.cuda(), y.long().cuda()\n",
        "            \n",
        "            pred = model(X.contiguous())\n",
        "            pred = F.interpolate(pred, size = cfg.DATASET.CROP_SIZE, mode = 'bilinear', align_corners = False)\n",
        "            losses = loss_fn(torch.squeeze(pred), y)\n",
        "            loss = losses.mean()   \n",
        "            ave_loss.update(loss.item())      \n",
        "\n",
        "    mean_IoU = 1 - ave_loss.average()\n",
        "\n",
        "    writer = writer_dict['writer']\n",
        "    global_steps = writer_dict['valid_global_steps']\n",
        "    writer.add_scalar('valid_loss', ave_loss.average(), global_steps)\n",
        "    writer.add_scalar('valid_mIoU', mean_IoU, global_steps)\n",
        "    for key, val in trainid2label.items():\n",
        "        if key != cfg.DATASET.IGNORE_LABEL and key != -1:\n",
        "            if val.name == 'traffic light':\n",
        "                val_name = \"traffic_light\"\n",
        "            elif val.name == 'traffic sign':\n",
        "                val_name = \"traffic_sign\"\n",
        "            else:\n",
        "                val_name = val.name\n",
        "    writer_dict['valid_global_steps'] = global_steps + 1\n",
        "        \n",
        "    return ave_loss.average(), mean_IoU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "046db724",
      "metadata": {
        "id": "046db724"
      },
      "outputs": [],
      "source": [
        "def run_train_loop():\n",
        "    \n",
        "    logger, final_output_dir, tb_log_dir = create_logger(cfg, cfg_name=cfg.NAME, phase='train')\n",
        "    \n",
        "    writer_dict = {'writer': SummaryWriter(tb_log_dir), 'train_global_steps': 0, 'valid_global_steps': 0}\n",
        "\n",
        "    best_mIoU = 0 # stores the best mean intersection over unit value\n",
        "    \n",
        "    start = timeit.default_timer()\n",
        "\n",
        "    for epoch in range(cfg.TRAIN.EPOCHS):\n",
        "        \n",
        "        e_start = time.time()\n",
        "\n",
        "        train(\n",
        "            cfg=cfg, \n",
        "            dataloader=train_dataloader,\n",
        "            model=model, \n",
        "            loss_fn=criterion, \n",
        "            optimizer=optimizer, \n",
        "            lr_scheduler=lr_scheduler,\n",
        "            epoch=epoch, \n",
        "            scaler=torch.cuda.amp.GradScaler(),\n",
        "            writer_dict=writer_dict\n",
        "        )\n",
        "\n",
        "        valid_loss, mean_IoU = validate(\n",
        "            cfg=cfg, \n",
        "            dataloader=valid_dataloader, \n",
        "            model=model,  \n",
        "            loss_fn=criterion,\n",
        "            writer_dict=writer_dict\n",
        "        )\n",
        "\n",
        "        # logger.info('=> saving checkpoint to {}'.format(final_output_dir + 'checkpoint.pth.tar'))\n",
        "\n",
        "        # saves the model after each epoch in a zipped format, overwritting the previous checkpoint\n",
        "        torch.save({\n",
        "            'epoch': epoch+1,\n",
        "            'best_mIoU': best_mIoU,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "        }, os.path.join(final_output_dir,'checkpoint.pth.tar'))\n",
        "\n",
        "        if mean_IoU > best_mIoU:\n",
        "            best_mIoU = mean_IoU\n",
        "            torch.save(model.state_dict(), os.path.join(final_output_dir, 'best.pth')) # saves the best model so far\n",
        "            \n",
        "        e_end = time.time()\n",
        "        t_epoch = e_end - e_start\n",
        "\n",
        "        msg = 'Epoch {}/{} --- {:.1f}s, Loss: {:.3f}, MeanIoU: {: 4.4f}, Best_mIoU: {: 4.4f}'.format(\n",
        "            epoch+1, cfg.TRAIN.EPOCHS, t_epoch, valid_loss, mean_IoU, best_mIoU)\n",
        "        logging.info(msg)\n",
        "        \n",
        "    torch.save(model.state_dict(), os.path.join(final_output_dir, 'final_state.pth')) # saves the final model\n",
        "    \n",
        "    writer_dict['writer'].close()\n",
        "    end = timeit.default_timer()\n",
        "    logger.info('Hours: %d' % np.int((end-start)/3600))\n",
        "    logger.info('Done')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cec33269",
      "metadata": {
        "scrolled": false,
        "id": "cec33269"
      },
      "outputs": [],
      "source": [
        "run_train_loop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9011fa1d",
      "metadata": {
        "id": "9011fa1d"
      },
      "outputs": [],
      "source": [
        "mean_IoU, pixel_acc, mean_acc = testval(\n",
        "    config, \n",
        "    eval_dataloader, \n",
        "    model, \n",
        "    sv_dir=cfg.OUTPUT_DIR, \n",
        "    sv_pred=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7897b601",
      "metadata": {
        "id": "7897b601"
      },
      "outputs": [],
      "source": [
        "print(\"mnea IoU: {:.3f}, mean Accuracy: {:.3f}, Pixel Accuracy: {:.3f}\".format(mean_IoU, mean_acc, pixel_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0e9ebf9",
      "metadata": {
        "id": "d0e9ebf9"
      },
      "outputs": [],
      "source": [
        "for key, val in trainid2label.items():\n",
        "    if key != cfg.DATASET.IGNORE_LABEL and key != -1:\n",
        "        print(\"{} --- IoU: {:.2f}\".format(val.name, IoU_array[key]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88bcf193",
      "metadata": {
        "id": "88bcf193"
      },
      "outputs": [],
      "source": [
        "print(trainid2label.items())\n",
        "\n",
        "\n",
        "\n",
        "labels = get_labels()\n",
        "\n",
        "labels = get_labels()\n",
        "id2label =      { label.id      : label for label in labels }\n",
        "trainid2label = { 0 : label for label in labels }"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}